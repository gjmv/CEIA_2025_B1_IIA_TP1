{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TP1: Algoritmos de búsqueda en Torre de Hanoi\n",
    "\n",
    "Integrantes:\n",
    "* Mealla Pablo\n",
    "* Mendoza Dante\n",
    "* Vasquez Jorge\n",
    "* Viñas Gustavo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 1. ¿Cuáles son los PEAS de este problema? (Performance, Environment, Actuators, Sensors)\n",
    "\n",
    "**Performance:**  \n",
    "Resolver correctamente la torre de Hanoi, esto es, que todos los discos queden ordenados en la última pila\n",
    "\n",
    "**Environment:**  \n",
    "  * Las tres torres\n",
    "  * Los discos\n",
    "  * Las reglas del juego\n",
    "  * Conocer el estado inicial\n",
    "  * Conocer el estado objetivo\n",
    "\n",
    "**Actuators:**  \n",
    "Movimientos de discos que se realiza en el Juego  \n",
    "Si fuera manual, sería nuestras manos que realizan el movimiento de discos  \n",
    "Si fuera una solución por software, sería una función que realiza el movimiento del disco: Programa (node.expand)\n",
    "\n",
    "**Sensors:**  \n",
    "Estado actual de los discos (node.state)  \n",
    "Si fuera manual, serían nuestros ojos que detectan la posición actual de los discos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. ¿Cuáles son las propiedades del entorno de trabajo?\n",
    "\n",
    "El entorno de trabajo es\n",
    "* Es totalmente observable, se pueden observar los discos en todo momento en las diferentes torres.\n",
    "* Deterministico, porque no hay azar en cambio de estados, y los cambios son decididos por el mismo agente.\n",
    "* Episódico, porque cada solución no depende de la anterior.\n",
    "* Estático, el ambiente no cambia mientras el agente esta tomando acciones.\n",
    "* Discreto, porque con cada movimiento obtengo un estado determinado.\n",
    "* Agente individual, porque estamos usando un solo agente para la resolución, aunque podría ser multiagente cooperativo si asignaramos ramas a distintos agentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. En el contexto de este problema, establezca cuáles son los: estado, espacio de estados, árbol de búsqueda, nodo de búsqueda, objetivo, acción y frontera.\n",
    "\n",
    "**Estado:**  \n",
    "Es la representación de los discos en las pilas para una combinación dada.\n",
    "\n",
    "**Espacio de estados:**  \n",
    "Son las posiciones válidas que pueden tomar los discos en las pilas.\n",
    "\n",
    "**Árbol de búsqueda:**  \n",
    "Es un diagrama del espacio de estados para encontrar una posible solución al problema de las torres de Hanoi. La raiz representa el estado \n",
    "inicial, las ramas representan los movimientos validos, los nodos representan todos los estados posibles y las hojas son los nodos frontera.\n",
    "\n",
    "**Nodo de búsqueda:**  ***** REVISAR *****  \n",
    "Es el estado a partir del cual analizo las acciones que se pueden tomar. Desde este nodo obtengo los siguientes estados posibles.\n",
    "\n",
    "**Objetivo:**  \n",
    "Es resolver la torre de Hanoi, es decir, que todos los discos esten ordenados en la última pila.\n",
    "\n",
    "**Acción:**  \n",
    "Es el movimiento válido de un disco de una pila hacia otra.\n",
    "\n",
    "**Frontera:**  \n",
    "Son los nodos no explorados (estados no explorados), es decir, próximos movimientos posibles aun no realizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Implemente algún método de búsqueda. Puedes elegir cualquiera menos búsqueda en anchura primero (el desarrollado en clase). Sos libre de elegir cualquiera de los vistos en clases, o inclusive buscar nuevos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_disks = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Profundidad primero\n",
    "\n",
    "from aima_libs.hanoi_states import ProblemHanoi, StatesHanoi\n",
    "from aima_libs.tree_hanoi import NodeHanoi\n",
    "from queue import LifoQueue\n",
    "\n",
    "def depth_first_search(number_disks=5):\n",
    "    # Inicializamos el problema\n",
    "    list_disks = [i for i in range(number_disks, 0, -1)]\n",
    "    initial_state = StatesHanoi(list_disks, [], [], max_disks=number_disks)\n",
    "    goal_state = StatesHanoi([], [], list_disks, max_disks=number_disks)\n",
    "    problem = ProblemHanoi(initial=initial_state, goal=goal_state)\n",
    "\n",
    "    # Creamos una cola LIFO con el nodo inicial\n",
    "    frontier = LifoQueue()\n",
    "    frontier.put(NodeHanoi(problem.initial))\n",
    "\n",
    "    # Creamos el set con estados ya visitados\n",
    "    explored = set()\n",
    "    \n",
    "    node_explored = 0\n",
    "    \n",
    "    while not frontier.empty():\n",
    "        node = frontier.get()\n",
    "        node_explored += 1\n",
    "        \n",
    "        # Agregamos el estado del nodo al set. Esto evita guardar duplicados, porque set nunca tiene elementos repetidos\n",
    "        explored.add(node.state)\n",
    "        \n",
    "        if problem.goal_test(node.state):  # Comprobamos si hemos alcanzado el estado objetivo\n",
    "            metrics = {\n",
    "                \"solution_found\": True,\n",
    "                \"nodes_explored\": node_explored,\n",
    "                \"states_visited\": len(explored),\n",
    "                \"nodes_in_frontier\": frontier.qsize(),\n",
    "                \"max_depth\": node.depth,\n",
    "                \"cost_total\": node.state.accumulated_cost,\n",
    "            }\n",
    "            return node, metrics\n",
    "        \n",
    "        # Agregamos a la cola todos los nodos sucesores del nodo actual\n",
    "        for next_node in node.expand(problem):\n",
    "            # Solo si el estado del nodo no fue explorado\n",
    "            if next_node.state not in explored:\n",
    "                frontier.put(next_node)\n",
    "\n",
    "    # Si no se encontro la solución, devolvemos la métricas igual\n",
    "    metrics = {\n",
    "        \"solution_found\": False,\n",
    "        \"nodes_explored\": node_explored,\n",
    "        \"states_visited\": len(explored),\n",
    "        \"nodes_in_frontier\": frontier.qsize(),\n",
    "        \"max_depth\": node.depth, # OBS: Si no se encontró la solución, este valor solo tiene sentido en breadth_first_search, en otros casos se debe ir llevando registro de cual fue la máxima profundidad\n",
    "        \"cost_total\": None,\n",
    "    }\n",
    "    return None, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution_found: True\n",
      "nodes_explored: 122\n",
      "states_visited: 122\n",
      "nodes_in_frontier: 63\n",
      "max_depth: 121\n",
      "cost_total: 121.0\n"
     ]
    }
   ],
   "source": [
    "solution, metrics = depth_first_search(number_disks=num_disks)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Greedy\n",
    "\n",
    "from aima_libs.hanoi_states import ProblemHanoi, StatesHanoi\n",
    "from aima_libs.tree_hanoi import NodeHanoi\n",
    "from aima_libs.aima import PriorityQueue as AimaPriorityQueue\n",
    "\n",
    "def priority_func(solution_last_rod, node):\n",
    "    # La heuristica es -1 por disco correctamente ubicado\n",
    "    last_rod = node.state.get_state()[-1]\n",
    "    h = 0\n",
    "    for i in range(0, min(len(last_rod), len(solution_last_rod))):\n",
    "        if (last_rod[i] != solution_last_rod[i]):\n",
    "            break\n",
    "        h -= 1\n",
    "    return h\n",
    "\n",
    "def greedy_search(number_disks=5):\n",
    "    # Inicializamos el problema\n",
    "    list_disks = [i for i in range(number_disks, 0, -1)]\n",
    "    initial_state = StatesHanoi(list_disks, [], [], max_disks=number_disks)\n",
    "    goal_state = StatesHanoi([], [], list_disks, max_disks=number_disks)\n",
    "    problem = ProblemHanoi(initial=initial_state, goal=goal_state)\n",
    "\n",
    "    # Creamos una cola priorizada, con funcion heuristica, que contenga el nodo inicial\n",
    "    solution_last_rod = problem.goal.get_state()[-1]\n",
    "    frontier = AimaPriorityQueue(order='min', f=lambda x: priority_func(solution_last_rod, x))\n",
    "    frontier.append(NodeHanoi(problem.initial))\n",
    "\n",
    "    # Creamos el set con estados ya visitados\n",
    "    explored = set()\n",
    "    \n",
    "    node_explored = 0\n",
    "    \n",
    "    while frontier.__len__() != 0:\n",
    "        _, node = frontier.pop()\n",
    "        node_explored += 1\n",
    "        \n",
    "        # Agregamos el estado del nodo al set. Esto evita guardar duplicados, porque set nunca tiene elementos repetidos\n",
    "        explored.add(node.state)\n",
    "        \n",
    "        if problem.goal_test(node.state):  # Comprobamos si hemos alcanzado el estado objetivo\n",
    "            metrics = {\n",
    "                \"solution_found\": True,\n",
    "                \"nodes_explored\": node_explored,\n",
    "                \"states_visited\": len(explored),\n",
    "                \"nodes_in_frontier\": frontier.__len__(),\n",
    "                \"max_depth\": node.depth,\n",
    "                \"cost_total\": node.state.accumulated_cost,\n",
    "            }\n",
    "            return node, metrics\n",
    "        \n",
    "        # Agregamos a la cola todos los nodos sucesores del nodo actual\n",
    "        for next_node in node.expand(problem):\n",
    "            # Solo si el estado del nodo no fue explorado\n",
    "            if next_node.state not in explored:\n",
    "                frontier.append(next_node)\n",
    "\n",
    "    # Si no se encontro la solución, devolvemos la métricas igual\n",
    "    metrics = {\n",
    "        \"solution_found\": False,\n",
    "        \"nodes_explored\": node_explored,\n",
    "        \"states_visited\": len(explored),\n",
    "        \"nodes_in_frontier\": frontier.__len__(),\n",
    "        \"max_depth\": node.depth, # OBS: Si no se encontró la solución, este valor solo tiene sentido en breadth_first_search, en otros casos se debe ir llevando registro de cual fue la máxima profundidad\n",
    "        \"cost_total\": None,\n",
    "    }\n",
    "    return None, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution_found: True\n",
      "nodes_explored: 160\n",
      "states_visited: 110\n",
      "nodes_in_frontier: 46\n",
      "max_depth: 31\n",
      "cost_total: 31.0\n"
     ]
    }
   ],
   "source": [
    "solution, metrics = greedy_search(number_disks=num_disks)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. ¿Qué complejidad en tiempo y memoria teórica tiene el algoritmo elegido?\n",
    "\n",
    "1. Búsqueda primero en profundidad\n",
    "   - Complejidad en tiempo teórica: en el peor caso, es O(b^m), siendo b el factor de ramificación (número promedio de ramificaciones por nodo) y m la máxima profundidad del espacio de estados.\n",
    "   - Complejidad en memoria teórica: O(b^d), siendo b el factor de ramificación y d la profundidad de la solución menos costosa, pues cada nodo generado permanece en memoria, almacenándose la mayor cantidad de nodos en el nivel meta.\n",
    "     \n",
    "2. Búsqueda Greedy\n",
    "   - Complejidad en tiempo teórica: La complejidad temporal de la búsqueda greedy depende de dos factores clave: Número de nodos en el espacio de búsqueda: Supongamos que hay N nodos en total. Tiempo para seleccionar el mejor nodo según la heurística: Usualmente se maneja con una estructura como una cola de prioridad (heap), que permite extraer el mejor nodo en O(log N). \n",
    "Entonces, la complejidad en tiempo es aproximadamente: 𝑂(𝑁⋅log(𝑁)). \n",
    "      * En el peor caso: Si la heurística no ayuda y explora todos los nodos, la complejidad se aproxima a O(N log N).\n",
    "      * En el mejor caso: Si la heurística guía directamente al objetivo, el tiempo puede ser cercano a O(d), donde d es la profundidad de la solución.\n",
    "   - Complejidad en memoria teórica: La búsqueda greedy mantiene en memoria:\n",
    "     1. Los nodos expandidos (visitados)\n",
    "     2. Los nodos frontera (los que están por expandirse)  \n",
    "   En el peor caso, podría almacenar todos los nodos del espacio de búsqueda, dando una complejidad de: O(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. A nivel implementación, ¿qué tiempo y memoria ocupa el algoritmo? (Se recomienda correr 10 veces y calcular promedio y desvío estándar de las métricas).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio pico de memoria ocupada para búsqueda primero en profundidad: 0.24 [MB] en 10 ejecuciones. Desvío estándar: 0.09.\n",
      "Promedio tiempo de ejecución para búsqueda primero en profundidad: 0.03 [s] en 10 ejecuciones. Desvío estándar: 0.0.\n"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "mem_peaks_mb = []\n",
    "time_measured = []\n",
    "\n",
    "for _ in range(0, 10):\n",
    "    tracemalloc.start()\n",
    "    start_time = time.time()\n",
    "\n",
    "    depth_first_search(number_disks=num_disks)\n",
    "    time_measured.append(time.time() - start_time)\n",
    "\n",
    "    # Para medir memoria consumida usamos el pico de memoria\n",
    "    _, memory_peak = tracemalloc.get_traced_memory()\n",
    "    memory_peak /= 1024*1024\n",
    "    mem_peaks_mb.append(memory_peak)\n",
    "    tracemalloc.stop()\n",
    "\n",
    "mean_mem = sum(mem_peaks_mb) / len(mem_peaks_mb)\n",
    "dev_mem = sqrt(sum([(x - mean_mem)**2 for x in mem_peaks_mb]) / (len(mem_peaks_mb)-1))\n",
    "print(f\"Promedio pico de memoria ocupada para búsqueda primero en profundidad: {round(mean_mem, 2)} [MB] en 10 ejecuciones. Desvío estándar: {round(dev_mem, 2)}.\", )\n",
    "\n",
    "mean_time = sum(time_measured) / len(time_measured)\n",
    "dev_time = sqrt(sum([(x - mean_time)**2 for x in time_measured]) / (len(time_measured)-1))\n",
    "print(f\"Promedio tiempo de ejecución para búsqueda primero en profundidad: {round(mean_time, 2)} [s] en 10 ejecuciones. Desvío estándar: {round(dev_time, 2)}.\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio pico de memoria ocupada para búsqueda greedy: 0.22 [MB] en 10 ejecuciones. Desvío estándar: 0.06.\n",
      "Promedio tiempo de ejecución para búsqueda greedy: 0.05 [s] en 10 ejecuciones. Desvío estándar: 0.0.\n"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "mem_peaks_mb = []\n",
    "time_measured = []\n",
    "\n",
    "for _ in range(0, 10):\n",
    "    tracemalloc.start()\n",
    "    start_time = time.time()\n",
    "\n",
    "    greedy_search(number_disks=num_disks)\n",
    "    time_measured.append(time.time() - start_time)\n",
    "\n",
    "    # Para medir memoria consumida usamos el pico de memoria\n",
    "    _, memory_peak = tracemalloc.get_traced_memory()\n",
    "    memory_peak /= 1024*1024\n",
    "    mem_peaks_mb.append(memory_peak)\n",
    "    tracemalloc.stop()\n",
    "\n",
    "mean_mem = sum(mem_peaks_mb) / len(mem_peaks_mb)\n",
    "dev_mem = sqrt(sum([(x - mean_mem)**2 for x in mem_peaks_mb]) / (len(mem_peaks_mb)-1))\n",
    "print(f\"Promedio pico de memoria ocupada para búsqueda greedy: {round(mean_mem, 2)} [MB] en 10 ejecuciones. Desvío estándar: {round(dev_mem, 2)}.\", )\n",
    "\n",
    "mean_time = sum(time_measured) / len(time_measured)\n",
    "dev_time = sqrt(sum([(x - mean_time)**2 for x in time_measured]) / (len(time_measured)-1))\n",
    "print(f\"Promedio tiempo de ejecución para búsqueda greedy: {round(mean_time, 2)} [s] en 10 ejecuciones. Desvío estándar: {round(dev_time, 2)}.\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Si la solución óptima es 2^k -1 movimientos con k igual al número de discos. Qué tan lejos está la solución del algoritmo implementado de esta solución óptima (se recomienda correr al menos 10 veces y usar el promedio de trayecto usado).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solución óptima para 5 discos: 2^5 - 1 = 31 movimientos\n",
    "\n",
    "1. Búsqueda primero en profundidad\n",
    "   - La solución del algoritmo requiere 121 movimientos, muy lejos de la cantidad óptima de movimientos\n",
    "     \n",
    "2. Búsqueda Greedy\n",
    "   - La solución del algoritmo requiere 31 movimientos, cantidad óptima de movimientos\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "B1_IIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
