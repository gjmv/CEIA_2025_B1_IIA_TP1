{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TP1: Algoritmos de búsqueda en Torre de Hanoi\n",
    "\n",
    "Integrantes:\n",
    "* Mealla Pablo\n",
    "* Mendoza Dante\n",
    "* Vasquez Jorge\n",
    "* Viñas Gustavo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 1. ¿Cuáles son los PEAS de este problema? (Performance, Environment, Actuators, Sensors)\n",
    "\n",
    "**Performance:**  \n",
    "Resolver correctamente la torre de Hanoi, esto es, que todos los discos queden ordenados en la última pila\n",
    "\n",
    "**Environment:**  \n",
    "  * Las tres torres\n",
    "  * Los discos\n",
    "  * Las reglas del juego\n",
    "  * Conocer el estado inicial\n",
    "  * Conocer el estado objetivo\n",
    "\n",
    "**Actuators:**  \n",
    "Movimientos de discos que se realiza en el Juego  \n",
    "Si fuera manual, sería nuestras manos que realizan el movimiento de discos  \n",
    "Si fuera una solución por software, sería una función que realiza el movimiento del disco: Programa (node.expand)\n",
    "\n",
    "**Sensors:**  \n",
    "Estado actual de los discos (node.state)  \n",
    "Si fuera manual, serían nuestros ojos que detectan la posición actual de los discos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. ¿Cuáles son las propiedades del entorno de trabajo?\n",
    "\n",
    "El entorno de trabajo es\n",
    "* Es totalmente observable, se pueden observar los discos en todo momento en las diferentes torres.\n",
    "* Deterministico, porque no hay azar en cambio de estados, y los cambios son decididos por el mismo agente.\n",
    "* Episódico, porque cada solución no depende de la anterior.\n",
    "* Estático, el ambiente no cambia mientras el agente esta tomando acciones.\n",
    "* Discreto, porque con cada movimiento obtengo un estado determinado.\n",
    "* Agente individual, porque estamos usando un solo agente para la resolución, aunque podría ser multiagente cooperativo si asignaramos ramas a distintos agentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. En el contexto de este problema, establezca cuáles son los: estado, espacio de estados, árbol de búsqueda, nodo de búsqueda, objetivo, acción y frontera.\n",
    "\n",
    "**Estado:**  \n",
    "Es la representación de los discos en las pilas para una combinación dada.\n",
    "\n",
    "**Espacio de estados:**  \n",
    "Son las posiciones válidas que pueden tomar los discos en las pilas.\n",
    "\n",
    "**Árbol de búsqueda:**  \n",
    "Es un diagrama del espacio de estados para encontrar una posible solución al problema de las torres de Hanoi. La raiz representa el estado \n",
    "inicial, las ramas representan los movimientos validos, los nodos representan todos los estados posibles y las hojas son los nodos frontera.\n",
    "\n",
    "**Nodo de búsqueda:**  \n",
    "Es el estado a partir del cual analizo las acciones que se pueden tomar. Desde este nodo obtengo los siguientes estados posibles.\n",
    "\n",
    "**Objetivo:**  \n",
    "Es resolver la torre de Hanoi, es decir, que todos los discos esten ordenados en la última pila.\n",
    "\n",
    "**Acción:**  \n",
    "Es el movimiento válido de un disco de una pila hacia otra.\n",
    "\n",
    "**Frontera:**  \n",
    "Son los nodos no explorados (estados no explorados), es decir, próximos movimientos posibles aun no realizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Implemente algún método de búsqueda. Puedes elegir cualquiera menos búsqueda en anchura primero (el desarrollado en clase). Sos libre de elegir cualquiera de los vistos en clases, o inclusive buscar nuevos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_disks = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Profundidad primero\n",
    "\n",
    "from aima_libs.hanoi_states import ProblemHanoi, StatesHanoi\n",
    "from aima_libs.tree_hanoi import NodeHanoi\n",
    "from queue import LifoQueue\n",
    "\n",
    "def depth_first_search(number_disks=5):\n",
    "    # Inicializamos el problema\n",
    "    list_disks = [i for i in range(number_disks, 0, -1)]\n",
    "    initial_state = StatesHanoi(list_disks, [], [], max_disks=number_disks)\n",
    "    goal_state = StatesHanoi([], [], list_disks, max_disks=number_disks)\n",
    "    problem = ProblemHanoi(initial=initial_state, goal=goal_state)\n",
    "\n",
    "    # Creamos una cola LIFO con el nodo inicial\n",
    "    frontier = LifoQueue()\n",
    "    frontier.put(NodeHanoi(problem.initial))\n",
    "\n",
    "    # Creamos el set con estados ya visitados\n",
    "    explored = set()\n",
    "    \n",
    "    node_explored = 0\n",
    "    \n",
    "    while not frontier.empty():\n",
    "        node = frontier.get()\n",
    "        node_explored += 1\n",
    "        \n",
    "        # Agregamos el estado del nodo al set. Esto evita guardar duplicados, porque set nunca tiene elementos repetidos\n",
    "        explored.add(node.state)\n",
    "        \n",
    "        if problem.goal_test(node.state):  # Comprobamos si hemos alcanzado el estado objetivo\n",
    "            metrics = {\n",
    "                \"solution_found\": True,\n",
    "                \"nodes_explored\": node_explored,\n",
    "                \"states_visited\": len(explored),\n",
    "                \"nodes_in_frontier\": frontier.qsize(),\n",
    "                \"max_depth\": node.depth,\n",
    "                \"cost_total\": node.state.accumulated_cost,\n",
    "            }\n",
    "            return node, metrics\n",
    "        \n",
    "        # Agregamos a la cola todos los nodos sucesores del nodo actual\n",
    "        for next_node in node.expand(problem):\n",
    "            # Solo si el estado del nodo no fue explorado\n",
    "            if next_node.state not in explored:\n",
    "                frontier.put(next_node)\n",
    "\n",
    "    # Si no se encontro la solución, devolvemos la métricas igual\n",
    "    metrics = {\n",
    "        \"solution_found\": False,\n",
    "        \"nodes_explored\": node_explored,\n",
    "        \"states_visited\": len(explored),\n",
    "        \"nodes_in_frontier\": frontier.qsize(),\n",
    "        \"max_depth\": node.depth, # OBS: Si no se encontró la solución, este valor solo tiene sentido en breadth_first_search, en otros casos se debe ir llevando registro de cual fue la máxima profundidad\n",
    "        \"cost_total\": None,\n",
    "    }\n",
    "    return None, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution_found: True\n",
      "nodes_explored: 122\n",
      "states_visited: 122\n",
      "nodes_in_frontier: 63\n",
      "max_depth: 121\n",
      "cost_total: 121.0\n"
     ]
    }
   ],
   "source": [
    "solution_depth_first, metrics = depth_first_search(number_disks=num_disks)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Greedy\n",
    "\n",
    "from aima_libs.hanoi_states import ProblemHanoi, StatesHanoi\n",
    "from aima_libs.tree_hanoi import NodeHanoi\n",
    "from aima_libs.aima import PriorityQueue as AimaPriorityQueue\n",
    "\n",
    "def priority_func(solution_last_rod, node):\n",
    "    # La heuristica es -1 por disco correctamente ubicado\n",
    "    last_rod = node.state.get_state()[-1]\n",
    "    h = 0\n",
    "    for i in range(0, min(len(last_rod), len(solution_last_rod))):\n",
    "        if (last_rod[i] != solution_last_rod[i]):\n",
    "            break\n",
    "        h -= 1\n",
    "    return h\n",
    "\n",
    "def greedy_search(number_disks=5):\n",
    "    # Inicializamos el problema\n",
    "    list_disks = [i for i in range(number_disks, 0, -1)]\n",
    "    initial_state = StatesHanoi(list_disks, [], [], max_disks=number_disks)\n",
    "    goal_state = StatesHanoi([], [], list_disks, max_disks=number_disks)\n",
    "    problem = ProblemHanoi(initial=initial_state, goal=goal_state)\n",
    "\n",
    "    # Creamos una cola priorizada, con funcion heuristica, que contenga el nodo inicial\n",
    "    solution_last_rod = problem.goal.get_state()[-1]\n",
    "    frontier = AimaPriorityQueue(order='min', f=lambda x: priority_func(solution_last_rod, x))\n",
    "    frontier.append(NodeHanoi(problem.initial))\n",
    "\n",
    "    # Creamos el set con estados ya visitados\n",
    "    explored = set()\n",
    "    \n",
    "    node_explored = 0\n",
    "    \n",
    "    while frontier.__len__() != 0:\n",
    "        _, node = frontier.pop()\n",
    "        node_explored += 1\n",
    "        \n",
    "        # Agregamos el estado del nodo al set. Esto evita guardar duplicados, porque set nunca tiene elementos repetidos\n",
    "        explored.add(node.state)\n",
    "        \n",
    "        if problem.goal_test(node.state):  # Comprobamos si hemos alcanzado el estado objetivo\n",
    "            metrics = {\n",
    "                \"solution_found\": True,\n",
    "                \"nodes_explored\": node_explored,\n",
    "                \"states_visited\": len(explored),\n",
    "                \"nodes_in_frontier\": frontier.__len__(),\n",
    "                \"max_depth\": node.depth,\n",
    "                \"cost_total\": node.state.accumulated_cost,\n",
    "            }\n",
    "            return node, metrics\n",
    "        \n",
    "        # Agregamos a la cola todos los nodos sucesores del nodo actual\n",
    "        for next_node in node.expand(problem):\n",
    "            # Solo si el estado del nodo no fue explorado\n",
    "            if next_node.state not in explored:\n",
    "                frontier.append(next_node)\n",
    "\n",
    "    # Si no se encontro la solución, devolvemos la métricas igual\n",
    "    metrics = {\n",
    "        \"solution_found\": False,\n",
    "        \"nodes_explored\": node_explored,\n",
    "        \"states_visited\": len(explored),\n",
    "        \"nodes_in_frontier\": frontier.__len__(),\n",
    "        \"max_depth\": node.depth, # OBS: Si no se encontró la solución, este valor solo tiene sentido en breadth_first_search, en otros casos se debe ir llevando registro de cual fue la máxima profundidad\n",
    "        \"cost_total\": None,\n",
    "    }\n",
    "    return None, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution_found: True\n",
      "nodes_explored: 160\n",
      "states_visited: 110\n",
      "nodes_in_frontier: 46\n",
      "max_depth: 31\n",
      "cost_total: 31.0\n"
     ]
    }
   ],
   "source": [
    "solution_greedy, metrics = greedy_search(number_disks=num_disks)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. ¿Qué complejidad en tiempo y memoria teórica tiene el algoritmo elegido?\n",
    "\n",
    "Algoritmo elegido: Greedy\n",
    "\n",
    "Considerando la siguientes condiciones:\n",
    "\n",
    "* Cantidad de discos = 5\n",
    "* Cantidad de Torres = 3\n",
    "* Una heurística de -1 para cada disco correctamente colocado en la Tercer torre. Es decir que se prioriza los movimientos que maximicen la cantidad de \n",
    "discos bien úbicados en la Tercer torre.\n",
    "* No se permiten estados repetidos.\n",
    "\n",
    "**Complejidad teórica en tiempo**\n",
    "\n",
    "Tiempo = Cantidad de estados ó nodos que explora el algoritmo antes de encontrar la solución.\n",
    "\n",
    "Número total de estados posibles para 5 discos y 3 torres, las combinaciones posibles son:\n",
    "\n",
    "\t3^5 = 243 estados posibles\n",
    "\n",
    "El mejor caso se da cuando la Heurística siempre elige el movimiento correcto:\n",
    "\n",
    "* Encuentra la solución rápidamente, explorando solo unos pocos estados.\n",
    "* Tiempo= Cercano a O(d), donde d es la profundidad de la solución óptima 2^n -1. La cantidad de movimientos ideales sería de 31 movimientos para 5 discos.\n",
    "\n",
    "    O(d) = O(31)\n",
    "\n",
    "Peor caso se da cuando:\n",
    "\n",
    "* Si la heurística no guía bien (es decir, el algoritmo sigue caminos subóptimos):\n",
    "* El algoritmo podría terminar explorando casi todos los 243 estados posibles antes de dar con la solución.\n",
    "\n",
    "    O(d)=O(243)\n",
    "\n",
    "\n",
    "**Complejidad teórica en memoria (nodos almacenados)**\n",
    "\n",
    "Memoria = cuántos estados guarda el algoritmo mientras busca la solución.\n",
    "Greedy almacena: \n",
    "\n",
    "* Nodos actuales más prometedores (los que tienen mejor heurística).\n",
    "* Estados visitados para no repetir configuraciones.\n",
    "\n",
    "Mejor caso (uso optimo de memoria):\n",
    "\n",
    "* Si la heurística guía bien y encuentra la solución directo:\n",
    "* Guarda pocos estados, solo los que explora (cerca de 31 nodos).\n",
    "\n",
    "Memoria mejor caso:\n",
    "  \n",
    "    O(31)\n",
    "\n",
    "Peor caso (memoria):\n",
    "\n",
    "* Si la heurística falla y explora casi todo:\n",
    "* Guarda todos los estados posibles (243 estados) para no repetirlos.\n",
    "\n",
    "\n",
    "Memoria peor caso:\n",
    "    \n",
    "    O(243)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. A nivel implementación, ¿qué tiempo y memoria ocupa el algoritmo? (Se recomienda correr 10 veces y calcular promedio y desvío estándar de las métricas).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio pico de memoria ocupada para búsqueda primero en profundidad: 0.23 [MB] en 10 ejecuciones. Desvío estándar: 0.04.\n",
      "Promedio tiempo de ejecución para búsqueda primero en profundidad: 0.03 [s] en 10 ejecuciones. Desvío estándar: 0.01.\n"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "mem_peaks_mb = []\n",
    "time_measured = []\n",
    "\n",
    "for _ in range(0, 10):\n",
    "    tracemalloc.start()\n",
    "    start_time = time.time()\n",
    "\n",
    "    depth_first_search(number_disks=num_disks)\n",
    "    time_measured.append(time.time() - start_time)\n",
    "\n",
    "    # Para medir memoria consumida usamos el pico de memoria\n",
    "    _, memory_peak = tracemalloc.get_traced_memory()\n",
    "    memory_peak /= 1024*1024\n",
    "    mem_peaks_mb.append(memory_peak)\n",
    "    tracemalloc.stop()\n",
    "\n",
    "mean_mem = sum(mem_peaks_mb) / len(mem_peaks_mb)\n",
    "dev_mem = sqrt(sum([(x - mean_mem)**2 for x in mem_peaks_mb]) / (len(mem_peaks_mb)-1))\n",
    "print(f\"Promedio pico de memoria ocupada para búsqueda primero en profundidad: {round(mean_mem, 2)} [MB] en 10 ejecuciones. Desvío estándar: {round(dev_mem, 2)}.\", )\n",
    "\n",
    "mean_time = sum(time_measured) / len(time_measured)\n",
    "dev_time = sqrt(sum([(x - mean_time)**2 for x in time_measured]) / (len(time_measured)-1))\n",
    "print(f\"Promedio tiempo de ejecución para búsqueda primero en profundidad: {round(mean_time, 2)} [s] en 10 ejecuciones. Desvío estándar: {round(dev_time, 2)}.\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio pico de memoria ocupada para búsqueda greedy: 0.23 [MB] en 10 ejecuciones. Desvío estándar: 0.1.\n",
      "Promedio tiempo de ejecución para búsqueda greedy: 0.04 [s] en 10 ejecuciones. Desvío estándar: 0.0.\n"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "mem_peaks_mb = []\n",
    "time_measured = []\n",
    "\n",
    "for _ in range(0, 10):\n",
    "    tracemalloc.start()\n",
    "    start_time = time.time()\n",
    "\n",
    "    greedy_search(number_disks=num_disks)\n",
    "    time_measured.append(time.time() - start_time)\n",
    "\n",
    "    # Para medir memoria consumida usamos el pico de memoria\n",
    "    _, memory_peak = tracemalloc.get_traced_memory()\n",
    "    memory_peak /= 1024*1024\n",
    "    mem_peaks_mb.append(memory_peak)\n",
    "    tracemalloc.stop()\n",
    "\n",
    "mean_mem = sum(mem_peaks_mb) / len(mem_peaks_mb)\n",
    "dev_mem = sqrt(sum([(x - mean_mem)**2 for x in mem_peaks_mb]) / (len(mem_peaks_mb)-1))\n",
    "print(f\"Promedio pico de memoria ocupada para búsqueda greedy: {round(mean_mem, 2)} [MB] en 10 ejecuciones. Desvío estándar: {round(dev_mem, 2)}.\", )\n",
    "\n",
    "mean_time = sum(time_measured) / len(time_measured)\n",
    "dev_time = sqrt(sum([(x - mean_time)**2 for x in time_measured]) / (len(time_measured)-1))\n",
    "print(f\"Promedio tiempo de ejecución para búsqueda greedy: {round(mean_time, 2)} [s] en 10 ejecuciones. Desvío estándar: {round(dev_time, 2)}.\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Si la solución óptima es 2^k -1 movimientos con k igual al número de discos. Qué tan lejos está la solución del algoritmo implementado de esta solución óptima (se recomienda correr al menos 10 veces y usar el promedio de trayecto usado).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solución óptima para 5 discos: 2^5 - 1 = 31 movimientos\n",
    "\n",
    "1. Búsqueda primero en profundidad\n",
    "   - La solución del algoritmo requiere 121 movimientos, muy lejos de la cantidad óptima de movimientos\n",
    "     \n",
    "2. Búsqueda Greedy\n",
    "   - La solución del algoritmo requiere 31 movimientos, cantidad óptima de movimientos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra - Ejecución de simulación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Archivos para simulacion\n",
    "\n",
    "solution_depth_first.generate_solution_for_simulator(initial_state_file=\"./depth_first_initial_state.json\", sequence_file=\"./depth_first_sequence.json\")\n",
    "\n",
    "solution_greedy.generate_solution_for_simulator(initial_state_file=\"./greedy_initial_state.json\", sequence_file=\"./greedy_sequence.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizar simulación de \"búsqueda en profundidad primero\" ejecutar:  \n",
    "`python3 ./simulation_depth_first_hanoi.py`\n",
    "\n",
    "Para visualizar simulación de \"búsqueda greedy\" ejecutar:  \n",
    "`python3 ./simulation_greedy_hanoi.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "B1_IIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
