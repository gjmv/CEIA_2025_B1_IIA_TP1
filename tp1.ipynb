{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TP1: Algoritmos de b√∫squeda en Torre de Hanoi\n",
    "\n",
    "Integrantes:\n",
    "* Mealla Pablo\n",
    "* Mendoza Dante\n",
    "* Vasquez Jorge\n",
    "* Vi√±as Gustavo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 1. ¬øCu√°les son los PEAS de este problema? (Performance, Environment, Actuators, Sensors)\n",
    "\n",
    "**Performance:**  \n",
    "Resolver correctamente la torre de Hanoi, esto es, que todos los discos queden ordenados en la √∫ltima pila\n",
    "\n",
    "**Environment:**  \n",
    "  * Las tres torres\n",
    "  * Los discos\n",
    "  * Las reglas del juego\n",
    "  * Conocer el estado inicial\n",
    "  * Conocer el estado objetivo\n",
    "\n",
    "**Actuators:**  \n",
    "Movimientos de discos que se realiza en el Juego  \n",
    "Si fuera manual, ser√≠a nuestras manos que realizan el movimiento de discos  \n",
    "Si fuera una soluci√≥n por software, ser√≠a una funci√≥n que realiza el movimiento del disco: Programa (node.expand)\n",
    "\n",
    "**Sensors:**  \n",
    "Estado actual de los discos (node.state)  \n",
    "Si fuera manual, ser√≠an nuestros ojos que detectan la posici√≥n actual de los discos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. ¬øCu√°les son las propiedades del entorno de trabajo?\n",
    "\n",
    "El entorno de trabajo es\n",
    "* Es totalmente observable, se pueden observar los discos en todo momento en las diferentes torres.\n",
    "* Deterministico, porque no hay azar en cambio de estados, y los cambios son decididos por el mismo agente.\n",
    "* Epis√≥dico, porque cada soluci√≥n no depende de la anterior.\n",
    "* Est√°tico, el ambiente no cambia mientras el agente esta tomando acciones.\n",
    "* Discreto, porque con cada movimiento obtengo un estado determinado.\n",
    "* Agente individual, porque estamos usando un solo agente para la resoluci√≥n, aunque podr√≠a ser multiagente cooperativo si asignaramos ramas a distintos agentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. En el contexto de este problema, establezca cu√°les son los: estado, espacio de estados, √°rbol de b√∫squeda, nodo de b√∫squeda, objetivo, acci√≥n y frontera.\n",
    "\n",
    "**Estado:**  \n",
    "Es la representaci√≥n de los discos en las pilas para una combinaci√≥n dada.\n",
    "\n",
    "**Espacio de estados:**  \n",
    "Son las posiciones v√°lidas que pueden tomar los discos en las pilas.\n",
    "\n",
    "**√Årbol de b√∫squeda:**  \n",
    "Es un diagrama del espacio de estados para encontrar una posible soluci√≥n al problema de las torres de Hanoi. La raiz representa el estado \n",
    "inicial, las ramas representan los movimientos validos, los nodos representan todos los estados posibles y las hojas son los nodos frontera.\n",
    "\n",
    "**Nodo de b√∫squeda:**  ***** REVISAR *****  \n",
    "Es el estado a partir del cual analizo las acciones que se pueden tomar. Desde este nodo obtengo los siguientes estados posibles.\n",
    "\n",
    "**Objetivo:**  \n",
    "Es resolver la torre de Hanoi, es decir, que todos los discos esten ordenados en la √∫ltima pila.\n",
    "\n",
    "**Acci√≥n:**  \n",
    "Es el movimiento v√°lido de un disco de una pila hacia otra.\n",
    "\n",
    "**Frontera:**  \n",
    "Son los nodos no explorados (estados no explorados), es decir, pr√≥ximos movimientos posibles aun no realizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Implemente alg√∫n m√©todo de b√∫squeda. Puedes elegir cualquiera menos b√∫squeda en anchura primero (el desarrollado en clase). Sos libre de elegir cualquiera de los vistos en clases, o inclusive buscar nuevos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_disks = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Profundidad primero\n",
    "\n",
    "from aima_libs.hanoi_states import ProblemHanoi, StatesHanoi\n",
    "from aima_libs.tree_hanoi import NodeHanoi\n",
    "from queue import LifoQueue\n",
    "\n",
    "def depth_first_search(number_disks=5):\n",
    "    # Inicializamos el problema\n",
    "    list_disks = [i for i in range(number_disks, 0, -1)]\n",
    "    initial_state = StatesHanoi(list_disks, [], [], max_disks=number_disks)\n",
    "    goal_state = StatesHanoi([], [], list_disks, max_disks=number_disks)\n",
    "    problem = ProblemHanoi(initial=initial_state, goal=goal_state)\n",
    "\n",
    "    # Creamos una cola LIFO con el nodo inicial\n",
    "    frontier = LifoQueue()\n",
    "    frontier.put(NodeHanoi(problem.initial))\n",
    "\n",
    "    # Creamos el set con estados ya visitados\n",
    "    explored = set()\n",
    "    \n",
    "    node_explored = 0\n",
    "    \n",
    "    while not frontier.empty():\n",
    "        node = frontier.get()\n",
    "        node_explored += 1\n",
    "        \n",
    "        # Agregamos el estado del nodo al set. Esto evita guardar duplicados, porque set nunca tiene elementos repetidos\n",
    "        explored.add(node.state)\n",
    "        \n",
    "        if problem.goal_test(node.state):  # Comprobamos si hemos alcanzado el estado objetivo\n",
    "            metrics = {\n",
    "                \"solution_found\": True,\n",
    "                \"nodes_explored\": node_explored,\n",
    "                \"states_visited\": len(explored),\n",
    "                \"nodes_in_frontier\": frontier.qsize(),\n",
    "                \"max_depth\": node.depth,\n",
    "                \"cost_total\": node.state.accumulated_cost,\n",
    "            }\n",
    "            return node, metrics\n",
    "        \n",
    "        # Agregamos a la cola todos los nodos sucesores del nodo actual\n",
    "        for next_node in node.expand(problem):\n",
    "            # Solo si el estado del nodo no fue explorado\n",
    "            if next_node.state not in explored:\n",
    "                frontier.put(next_node)\n",
    "\n",
    "    # Si no se encontro la soluci√≥n, devolvemos la m√©tricas igual\n",
    "    metrics = {\n",
    "        \"solution_found\": False,\n",
    "        \"nodes_explored\": node_explored,\n",
    "        \"states_visited\": len(explored),\n",
    "        \"nodes_in_frontier\": frontier.qsize(),\n",
    "        \"max_depth\": node.depth, # OBS: Si no se encontr√≥ la soluci√≥n, este valor solo tiene sentido en breadth_first_search, en otros casos se debe ir llevando registro de cual fue la m√°xima profundidad\n",
    "        \"cost_total\": None,\n",
    "    }\n",
    "    return None, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution_found: True\n",
      "nodes_explored: 122\n",
      "states_visited: 122\n",
      "nodes_in_frontier: 63\n",
      "max_depth: 121\n",
      "cost_total: 121.0\n"
     ]
    }
   ],
   "source": [
    "solution, metrics = depth_first_search(number_disks=num_disks)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Greedy\n",
    "\n",
    "from aima_libs.hanoi_states import ProblemHanoi, StatesHanoi\n",
    "from aima_libs.tree_hanoi import NodeHanoi\n",
    "from aima_libs.aima import PriorityQueue as AimaPriorityQueue\n",
    "\n",
    "def priority_func(solution_last_rod, node):\n",
    "    # La heuristica es -1 por disco correctamente ubicado\n",
    "    last_rod = node.state.get_state()[-1]\n",
    "    h = 0\n",
    "    for i in range(0, min(len(last_rod), len(solution_last_rod))):\n",
    "        if (last_rod[i] != solution_last_rod[i]):\n",
    "            break\n",
    "        h -= 1\n",
    "    return h\n",
    "\n",
    "def greedy_search(number_disks=5):\n",
    "    # Inicializamos el problema\n",
    "    list_disks = [i for i in range(number_disks, 0, -1)]\n",
    "    initial_state = StatesHanoi(list_disks, [], [], max_disks=number_disks)\n",
    "    goal_state = StatesHanoi([], [], list_disks, max_disks=number_disks)\n",
    "    problem = ProblemHanoi(initial=initial_state, goal=goal_state)\n",
    "\n",
    "    # Creamos una cola priorizada, con funcion heuristica, que contenga el nodo inicial\n",
    "    solution_last_rod = problem.goal.get_state()[-1]\n",
    "    frontier = AimaPriorityQueue(order='min', f=lambda x: priority_func(solution_last_rod, x))\n",
    "    frontier.append(NodeHanoi(problem.initial))\n",
    "\n",
    "    # Creamos el set con estados ya visitados\n",
    "    explored = set()\n",
    "    \n",
    "    node_explored = 0\n",
    "    \n",
    "    while frontier.__len__() != 0:\n",
    "        _, node = frontier.pop()\n",
    "        node_explored += 1\n",
    "        \n",
    "        # Agregamos el estado del nodo al set. Esto evita guardar duplicados, porque set nunca tiene elementos repetidos\n",
    "        explored.add(node.state)\n",
    "        \n",
    "        if problem.goal_test(node.state):  # Comprobamos si hemos alcanzado el estado objetivo\n",
    "            metrics = {\n",
    "                \"solution_found\": True,\n",
    "                \"nodes_explored\": node_explored,\n",
    "                \"states_visited\": len(explored),\n",
    "                \"nodes_in_frontier\": frontier.__len__(),\n",
    "                \"max_depth\": node.depth,\n",
    "                \"cost_total\": node.state.accumulated_cost,\n",
    "            }\n",
    "            return node, metrics\n",
    "        \n",
    "        # Agregamos a la cola todos los nodos sucesores del nodo actual\n",
    "        for next_node in node.expand(problem):\n",
    "            # Solo si el estado del nodo no fue explorado\n",
    "            if next_node.state not in explored:\n",
    "                frontier.append(next_node)\n",
    "\n",
    "    # Si no se encontro la soluci√≥n, devolvemos la m√©tricas igual\n",
    "    metrics = {\n",
    "        \"solution_found\": False,\n",
    "        \"nodes_explored\": node_explored,\n",
    "        \"states_visited\": len(explored),\n",
    "        \"nodes_in_frontier\": frontier.__len__(),\n",
    "        \"max_depth\": node.depth, # OBS: Si no se encontr√≥ la soluci√≥n, este valor solo tiene sentido en breadth_first_search, en otros casos se debe ir llevando registro de cual fue la m√°xima profundidad\n",
    "        \"cost_total\": None,\n",
    "    }\n",
    "    return None, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution_found: True\n",
      "nodes_explored: 160\n",
      "states_visited: 110\n",
      "nodes_in_frontier: 46\n",
      "max_depth: 31\n",
      "cost_total: 31.0\n"
     ]
    }
   ],
   "source": [
    "solution, metrics = greedy_search(number_disks=num_disks)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. ¬øQu√© complejidad en tiempo y memoria te√≥rica tiene el algoritmo elegido?\n",
    "\n",
    "1. B√∫squeda primero en profundidad\n",
    "   - Complejidad en tiempo te√≥rica: en el peor caso, es O(b^m), siendo b el factor de ramificaci√≥n (n√∫mero promedio de ramificaciones por nodo) y m la m√°xima profundidad del espacio de estados.\n",
    "   - Complejidad en memoria te√≥rica: O(b^d), siendo b el factor de ramificaci√≥n y d la profundidad de la soluci√≥n menos costosa, pues cada nodo generado permanece en memoria, almacen√°ndose la mayor cantidad de nodos en el nivel meta.\n",
    "     \n",
    "2. B√∫squeda Greedy\n",
    "   - Complejidad en tiempo te√≥rica: La complejidad temporal de la b√∫squeda greedy depende de dos factores clave: N√∫mero de nodos en el espacio de b√∫squeda: Supongamos que hay N nodos en total. Tiempo para seleccionar el mejor nodo seg√∫n la heur√≠stica: Usualmente se maneja con una estructura como una cola de prioridad (heap), que permite extraer el mejor nodo en O(log N). \n",
    "Entonces, la complejidad en tiempo es aproximadamente: ùëÇ(ùëÅ‚ãÖlog(ùëÅ)). \n",
    "      * En el peor caso: Si la heur√≠stica no ayuda y explora todos los nodos, la complejidad se aproxima a O(N log N).\n",
    "      * En el mejor caso: Si la heur√≠stica gu√≠a directamente al objetivo, el tiempo puede ser cercano a O(d), donde d es la profundidad de la soluci√≥n.\n",
    "   - Complejidad en memoria te√≥rica: La b√∫squeda greedy mantiene en memoria:\n",
    "     1. Los nodos expandidos (visitados)\n",
    "     2. Los nodos frontera (los que est√°n por expandirse)  \n",
    "   En el peor caso, podr√≠a almacenar todos los nodos del espacio de b√∫squeda, dando una complejidad de: O(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. A nivel implementaci√≥n, ¬øqu√© tiempo y memoria ocupa el algoritmo? (Se recomienda correr 10 veces y calcular promedio y desv√≠o est√°ndar de las m√©tricas).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio pico de memoria ocupada para b√∫squeda primero en profundidad: 0.24 [MB] en 10 ejecuciones. Desv√≠o est√°ndar: 0.09.\n",
      "Promedio tiempo de ejecuci√≥n para b√∫squeda primero en profundidad: 0.03 [s] en 10 ejecuciones. Desv√≠o est√°ndar: 0.0.\n"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "mem_peaks_mb = []\n",
    "time_measured = []\n",
    "\n",
    "for _ in range(0, 10):\n",
    "    tracemalloc.start()\n",
    "    start_time = time.time()\n",
    "\n",
    "    depth_first_search(number_disks=num_disks)\n",
    "    time_measured.append(time.time() - start_time)\n",
    "\n",
    "    # Para medir memoria consumida usamos el pico de memoria\n",
    "    _, memory_peak = tracemalloc.get_traced_memory()\n",
    "    memory_peak /= 1024*1024\n",
    "    mem_peaks_mb.append(memory_peak)\n",
    "    tracemalloc.stop()\n",
    "\n",
    "mean_mem = sum(mem_peaks_mb) / len(mem_peaks_mb)\n",
    "dev_mem = sqrt(sum([(x - mean_mem)**2 for x in mem_peaks_mb]) / (len(mem_peaks_mb)-1))\n",
    "print(f\"Promedio pico de memoria ocupada para b√∫squeda primero en profundidad: {round(mean_mem, 2)} [MB] en 10 ejecuciones. Desv√≠o est√°ndar: {round(dev_mem, 2)}.\", )\n",
    "\n",
    "mean_time = sum(time_measured) / len(time_measured)\n",
    "dev_time = sqrt(sum([(x - mean_time)**2 for x in time_measured]) / (len(time_measured)-1))\n",
    "print(f\"Promedio tiempo de ejecuci√≥n para b√∫squeda primero en profundidad: {round(mean_time, 2)} [s] en 10 ejecuciones. Desv√≠o est√°ndar: {round(dev_time, 2)}.\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio pico de memoria ocupada para b√∫squeda greedy: 0.22 [MB] en 10 ejecuciones. Desv√≠o est√°ndar: 0.06.\n",
      "Promedio tiempo de ejecuci√≥n para b√∫squeda greedy: 0.05 [s] en 10 ejecuciones. Desv√≠o est√°ndar: 0.0.\n"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "mem_peaks_mb = []\n",
    "time_measured = []\n",
    "\n",
    "for _ in range(0, 10):\n",
    "    tracemalloc.start()\n",
    "    start_time = time.time()\n",
    "\n",
    "    greedy_search(number_disks=num_disks)\n",
    "    time_measured.append(time.time() - start_time)\n",
    "\n",
    "    # Para medir memoria consumida usamos el pico de memoria\n",
    "    _, memory_peak = tracemalloc.get_traced_memory()\n",
    "    memory_peak /= 1024*1024\n",
    "    mem_peaks_mb.append(memory_peak)\n",
    "    tracemalloc.stop()\n",
    "\n",
    "mean_mem = sum(mem_peaks_mb) / len(mem_peaks_mb)\n",
    "dev_mem = sqrt(sum([(x - mean_mem)**2 for x in mem_peaks_mb]) / (len(mem_peaks_mb)-1))\n",
    "print(f\"Promedio pico de memoria ocupada para b√∫squeda greedy: {round(mean_mem, 2)} [MB] en 10 ejecuciones. Desv√≠o est√°ndar: {round(dev_mem, 2)}.\", )\n",
    "\n",
    "mean_time = sum(time_measured) / len(time_measured)\n",
    "dev_time = sqrt(sum([(x - mean_time)**2 for x in time_measured]) / (len(time_measured)-1))\n",
    "print(f\"Promedio tiempo de ejecuci√≥n para b√∫squeda greedy: {round(mean_time, 2)} [s] en 10 ejecuciones. Desv√≠o est√°ndar: {round(dev_time, 2)}.\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Si la soluci√≥n √≥ptima es 2^k -1 movimientos con k igual al n√∫mero de discos. Qu√© tan lejos est√° la soluci√≥n del algoritmo implementado de esta soluci√≥n √≥ptima (se recomienda correr al menos 10 veces y usar el promedio de trayecto usado).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soluci√≥n √≥ptima para 5 discos: 2^5 - 1 = 31 movimientos\n",
    "\n",
    "1. B√∫squeda primero en profundidad\n",
    "   - La soluci√≥n del algoritmo requiere 121 movimientos, muy lejos de la cantidad √≥ptima de movimientos\n",
    "     \n",
    "2. B√∫squeda Greedy\n",
    "   - La soluci√≥n del algoritmo requiere 31 movimientos, cantidad √≥ptima de movimientos\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "B1_IIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
